# 基于 TensorFlow 的深度学习图像识别模型的自动化测试

### 项目介绍

#### 任务目标：

- 针对深度学习图像识别模型的自动化测试框架，设计并实现一个 Python 实现

的基于 TensorFlow 的深度学习图像识别模型的自动化测试方法，采用特定的方

式，根据提供的训练数据集和待测数据集，由待测数据集尽量生成使得模型出错但

是和原始数据“相似度”高的测试数据。

#### 测试对象：

- 针对某个图像识别模型的待测数据集进行测试。对模型未知，对训练数据集和

待测数据集已知。其中训练数据集将使用 Fashion-MNIST 数据集。（黑盒测试）

### 代码结构

![image-20191121223937179](C:\Users\SKY\AppData\Roaming\Typora\typora-user-images\image-20191121223937179.png)

- attack_data (dir)、test_data (dir)、generate.py (file)、model.h5(file) 在根目录下

### 如何运行

- 运行**main.py**:

  - **注意**： **tensorflow 版本**为**2.0.0** ，**python** 版本为 **3.7**
  - 根据 test_data**生成**并且**储存**10000 个对抗样本，打印一些运行参数
    - 打印下文“**生成对抗样本时间**”章节中提到的东西
  - 调节 main 函数中的 count 可以改变输入的样本数量（前 count 个）

- 运行**generate.py**：
  - 根据 test_data**生成**100 个对抗样本，用于**测试**
  - 调节 main 函数中的 count 可以改变输入的样本数量（前 count 个）
  - main 函数里面有很多被注释掉的代码，取消注释可以运行（不一定能运行成功），执行一些额外功能，比如内存监控，模型评估等等。
- 单独调用 generate.py 中的**generate 函数**：
  - 可接受归一化的图片或者非归一化的图片
  - shape 参数表示输入数据的形状，比如(1000,28,28,1)
  - 输出为“归一化”之后的图片数据
- 运行**getModel.py**：
  - 生成模型( model.h5 )
- 运行**show.py**：
  - **注意**： 需要额外引入 **matplotlib** 模块
  - 生成 10 张样本图片攻击前后的对比
  - 调节 show(index)函数的 index 参数，可以显示从 index 开始的十张图片
- **model.h5** 以及 **model 文件夹**：
  - model.h5
    - 通过 model = keras.models.load_model("model.h5") 的方式载入
    - 使用 model.predict 进行预测，model.evaluate 来评估模型
    - 使用此模型有内存泄漏风险
  - model 文件夹
    - 通过 model = tf.keras.experimental.load_from_saved_model("model") 载入
    - 使用 model.predict 进行预测，不能评估模型
    - 使用该模型预测速度极快，且不存在内存泄漏风险

### 生成对抗样本时间

- 总共用时 13 分 40 秒

- generate.py 中 main 函数打印结果：
  - No.10000 Success: 9832/10000 Success_rate: 0.98 Runtime: 800.14s sim: 0.84
    - No. 表示第 10000 用例
    - Sucess 表示攻击成功个数
    - Success_rate 表示攻击成功比例
    - Runtime 表示运行时间
      - 10000 用例总共约耗时 800.14s ， 约 13 分 20 秒
    - sim： 表示第 No.n 个样本的结构相似性

### 算法详解

- 先是受到单像素点攻击的启发，决定随机攻击图片上面的像素点
- 以文献《[ Simple Black-box Adversarial Attacks ](http://proceedings.mlr.press/v97/guo19a/guo19a.pdf)》描述的算法作为基本思想

![image-20191121210724250](C:\Users\SKY\AppData\Roaming\Typora\typora-user-images\image-20191121210724250.png)

- 其中，x 表示输入的图片，y 表示预期输出，我的算法中使用了预期的标签作为 y，epsilon 表示攻击程度,另外在我的算法中忽略了 Q 变量。
- 算法中，p 表示预测成功的概率，即生成预期标签的概率，这里需要使用到训练出的模型来计算。 ( model.predict() )。
- 随机产生攻击位置，先正向改变像素点的值(加上 epsilon)，如果 p 没有下降，再反向改变像素的值( 减去 epsilon )。如果攻击成功，将攻击的位置标记为攻击成功，并且将 p 赋值为 p'，p'表示降低后的预测值。如果两次攻击均失败，即 p 没有下降，则将位置标记为攻击无效，之后不再攻击这些点。
- 当攻击成功次数达到一定值、或者尝试攻击次数达到一定值（为了防止死循环，即一直攻击失败）、或者攻击成功（当 label 对应的预测值 p 小于某个程度之后，可以看成是攻击成功）。
- 但是最终发现单像素点攻击的效果不好，于是想到将攻击成功的像素延展开来，以某种规则攻击附近像素。经过研究发现，以该像素为中心的十字形攻击方式效果出乎意外的好，于是采用此法进行攻击。
- 采用十字形法攻击时，如果某次攻击不成功，则将十字所覆盖的范围全部标记为攻击无效，以后不再攻击。
- 最终，用该算法生成的对抗样本来评估原模型，发现原模型针对对抗样本准确率下降到了 8.66%，另外对抗样本与原模型的平均结构相似度(ssim)是 85%左右，说明攻击效果不错。
- 另外，直接用该算法攻击实际上的攻击成功率不到90%，攻击对抗样本只能让准确度下降到17%，于是我将剩下没有攻击成功的10%提取出来用另一个简单算法重新攻击了一遍。最后攻击成功率达到98%，攻击对抗样本让准确度下降到8.66%。
- 另一个算法描述如下：
  - 产生随机的攻击位置和一个随机的颜色(并归一化)
  - 十字形法攻击该位置和附近的点，要做到攻击一次就将准确度降到30%以下
  - 如果准确率降到30%以下，表示攻击成功，退出循环；否则重新执行该过程，或者执行完一定次数后退出。

### 个人感受

- 一开始其实是最难的，因为对机器学习基本上一无所知。甚至不知道搜索的关键词是什么。后来将范围逐渐缩小，大概明白大作业分为两个步骤，首先是训练模型，然后是通过利用模型生成对抗样本。
- 训练模型其实没怎么花时间，很多博客上写的比较清楚； 但是黑盒攻击相关的信息就非常少了。甚至很多链接，标题写的是黑盒测试，但是实际内容是白盒测试。
- 最后在国内的博客上找到了一种方法，就是像素点攻击方法。然后又去查国内外的文献，发现了上文所述的简单有效的黑盒攻击方式，于是开始着手编写黑盒攻击相关代码。
- 开始是基于像素点攻击的，跑出来的结果并不理想，无论怎么调参，攻击成功率都十分低，或者说该方法只针对某些图片效果比较好，但是对另一些图片无能为力。
- 在一番资料查阅以及和同学讨论之后，发现了一种成功率比较高的攻击方式，就是上文所述的十字形攻击方法。在使用该方法以后，攻击成功率大大提升。然后又花了一些心思调参，最终代码定型。
- 在跑比较少的样本的时候代码显得没问题，但是，当样本大于 800 左右的时候，控制台总会异常地崩溃。后来追根朔源，发现是内存泄漏引起的。于是查阅了相关资料，通过一些测试方法发现是 tensorflow 导致地内存泄漏。之后又查阅了无数资料都无法解决内存溢出的问题。于是只能减缓代码运行速度，让代码有充分的时间进入虚拟内存，使进程不至于被操作系统突然杀死。
- 当我以为就这么结束了的时候，某同学突然找到了一种解决办法，就是将模型以某种不被推荐的方式存入文件夹之中，这样读取出来的模型就不会存在内存泄漏问题。当然，更为奇妙的是，以这种方式读取出来的模型大大提高了代码运行速率（ 之前每秒能处理 3 张图，处理完 10000 张得用 1 个小时；之后每秒能处理 12 张图，速度提升了 4 倍）。
- 总的来说，这次作业不但让我了解了机器学习的知识，更重要的是，锻炼了我从零开始做好一件事情的能力，以及解决各种问题的能力。

### 参考文献和网址

- 《[ Simple Black-box Adversarial Attacks ](http://proceedings.mlr.press/v97/guo19a/guo19a.pdf)》

- [利用 TensorFlow 进行 Fashion MNIST 数据集的基本分类问题](https://blog.csdn.net/m0_37393514/article/details/81010587)

- [One pixel 对抗攻击\_学习笔记](https://blog.csdn.net/qq_35414569/article/details/82148305)
